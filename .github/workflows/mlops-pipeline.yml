name: MLOps Pipeline with Model Drift Monitoring

on:
  push:
    paths:
      - 'audit_data.csv'
      - 'ml_model_training.py'
      - 'main.py'
      - 'drift_monitor.py'
  pull_request:
    paths:
      - 'audit_data.csv'
      - 'ml_model_training.py'
      - 'main.py'
      - 'drift_monitor.py'
  workflow_dispatch:

jobs:
  train-and-deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Setup Python 3.9
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Validate Data Quality
      run: |
        echo "Data Quality Check..."
        python -c "
        import pandas as pd
        df = pd.read_csv('audit_data.csv')
        print(f'Dataset shape: {df.shape}')
        print(f'Missing values: {df.isnull().sum().sum()}')
        assert df.shape[0] > 700, 'Dataset too small'
        print('Data Quality: OK')
        "

    - name: Setup MLflow Server
      run: |
        echo "Starting MLflow Server..."
        mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db &
        
        echo "Waiting for MLflow to be ready..."
        for i in {1..30}; do
          if curl -s http://localhost:5000/health > /dev/null 2>&1; then
            echo "MLflow is ready!"
            break
          fi
          echo "Attempt $i/30: MLflow not ready yet, waiting..."
          sleep 2
        done
        
        # Final check
        curl -f http://localhost:5000/health || echo "MLflow health check failed, but continuing..."

    - name: Run Model Training
      run: |
        echo "Training ML Model..."
        python ml_model_training.py

    - name: Model Drift Monitoring Check
      id: drift_check
      run: |
        echo "Checking for Model Performance Drift..."
        python drift_monitor.py
        
        if [ -f "model_drift_report.json" ]; then
          DRIFT_DETECTED=$(python -c "
          import json
          with open('model_drift_report.json') as f:
              data = json.load(f)
          print('true' if data.get('drift_detected', False) else 'false')
          ")
          echo "drift_detected=$DRIFT_DETECTED" >> $GITHUB_OUTPUT
          
          python -c "
          import json
          with open('model_drift_report.json') as f:
              data = json.load(f)
          print('Model Drift Report Summary:')
          print(f\"   Status: {'DRIFT DETECTED' if data.get('drift_detected') else 'OK'}\")
          print(f\"   Recommendation: {data.get('recommendation', 'Unknown')}\")
          if 'estimated_performance' in data:
              print(f\"   Estimated Performance: {data['estimated_performance']:.3f}\")
          "
        else
          echo "drift_detected=false" >> $GITHUB_OUTPUT
        fi

    - name: Build Containers
      run: |
        echo "Building Docker Containers..."
        docker-compose build

    - name: Test Container Functionality
      run: |
        echo "Testing Container Setup..."
        docker-compose up -d
        sleep 30
        
        curl -f http://localhost:5000/health || echo "MLflow container check"
        curl -f http://localhost:8000/health || echo "FastAPI container check"
        
        docker-compose down

    - name: Model Drift Alert
      if: steps.drift_check.outputs.drift_detected == 'true'
      run: |
        echo "MODEL DRIFT DETECTED!"
        echo "Model Performance-Degradation wurde erkannt."
        echo "Empfehlung: Model-Retraining erforderlich"

    - name: Pipeline Success Report
      if: steps.drift_check.outputs.drift_detected == 'false'
      run: |
        echo "MLOps Pipeline erfolgreich abgeschlossen!"
        echo "Model Training: OK"
        echo "Container Build: OK"
        echo "Model Performance: OK"
        echo "System ist bereit f√ºr Production Deployment!"

    - name: Archive Model Drift Report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: model-drift-report
        path: model_drift_report.json